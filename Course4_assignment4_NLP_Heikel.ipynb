{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "import sklearn\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class label: neg\n",
      "text: In the first one it was mainly giant rats, but there were some wasps and a giant chicken too. This one, however, is just giant rats period, well giant rats and one really growing little boy. This one is about this growing boy and a scientist that is trying to help him so he accidentally creates giant killer rats...you know how it is. This movie has some kills and its moments, but I find it to be on par with the original, I just prefer some variety in my giant creature movies. Well, that is not true...I actually like \\Empire of the Ants\\\", maybe I just do not care for giant rodents. All in all a rather drab movie though it does have one rather odd turn of events in this one dream sequence that is truly bizarre. I just can't recommend this one.\"\n"
     ]
    }
   ],
   "source": [
    "with open(\"imdb_train.json\") as f:\n",
    "    data=json.load(f)\n",
    "random.shuffle(data) #play it safe! (why?)\n",
    "print(\"class label:\", data[0][\"class\"])\n",
    "print(\"text:\",data[0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts=[one_example[\"text\"] for one_example in data]\n",
    "labels=[one_example[\"class\"] for one_example in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'neg': 12500, 'pos': 12500})"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(labels) # balanced number of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This many texts 25000\n",
      "This many labels 25000\n",
      "\n",
      "neg The premise is ridiculous, the characters unbeliev...\n",
      "neg If you have seen very less films, this might be a ...\n",
      "neg My title ought to be enough.  It baffles me that a...\n",
      "pos i got to see the whole movie last night and i foun...\n",
      "pos I watched this film so many times through my child...\n",
      "neg This movie is not as horrible as most Sci-Fi Chann...\n",
      "neg Having the In-Laws over for the weekend? Then this...\n",
      "pos This is the moving tale of Scotland's legendary he...\n",
      "pos Fabulous film! Rented the DVD recently and was flo...\n",
      "pos Yes its an art... to successfully make a slow pace...\n",
      "pos I have seen this movie and even though I kind of k...\n",
      "pos As a convert into the Church of Jesus Christ of La...\n",
      "neg Serge Farnel made a very precise critics of this f...\n",
      "pos Well, when before I saw this film I really wasn't ...\n",
      "neg Damn, I thought I'd seen some bad westerns. Can't ...\n",
      "neg Zombie Nation 2004 R  Hey, I was bored. I looked i...\n",
      "neg OK this movie was made for one reason and one reas...\n",
      "pos This is a feel-good movie and nothing more. And fo...\n",
      "neg Back in the 70's, when I had first seen this, I wa...\n",
      "neg The fact that someone actually spent money on such...\n"
     ]
    }
   ],
   "source": [
    "print(\"This many texts\",len(texts))\n",
    "print(\"This many labels\",len(labels))\n",
    "print()\n",
    "for label,text in list(zip(labels,texts))[:20]:\n",
    "    print(label,text[:50]+\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Test sklearn’s TfidfVectorizer in place of CountVectorizer on the IMDB data. Do you see any difference in the classification results or the optimal C value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape= (25000, 74849)\n",
      "what did we get? -> <class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer=CountVectorizer(max_features=100000,binary=True,ngram_range=(1,1))\n",
    "feature_matrix_count=vectorizer.fit_transform(texts)\n",
    "print(\"shape=\",feature_matrix_count.shape)\n",
    "print(\"what did we get? ->\", feature_matrix_count.__class__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def split_data_get_feature_matrix(text, labels, Vectorizer=CountVectorizer, ngram_range=(1, 1)):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    train_texts, dev_texts, train_labels, dev_labels=train_test_split(texts,labels,test_size=0.2)\n",
    "    \n",
    "    vectorizer=Vectorizer(max_features=100000,binary=True,ngram_range=ngram_range)\n",
    "        \n",
    "    feature_matrix_train=vectorizer.fit_transform(train_texts)\n",
    "    feature_matrix_dev=vectorizer.transform(dev_texts)\n",
    "    \n",
    "    split_dict = {'train_texts': train_texts, \n",
    "                  'dev_texts': dev_texts, \n",
    "                  'train_labels':train_labels,\n",
    "                  'dev_labels':dev_labels,\n",
    "                  'feature_matrix_train':feature_matrix_train,\n",
    "                  'feature_matrix_dev':feature_matrix_dev}\n",
    "    \n",
    "    return split_dict, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_searchSVC(X_train, y_train):\n",
    "    from sklearn.svm import LinearSVC\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    \n",
    "    param_grid =  [{'C': [0.001, 0.01, 0.1, 1, 10, 120]}]        \n",
    "\n",
    "    grid_search = GridSearchCV(LinearSVC(), param_grid, cv=5)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_svm_results(split_dict, c=1):\n",
    "    classifier=sklearn.svm.LinearSVC(C=c)\n",
    "    classifier.fit(split_dict['feature_matrix_train'], split_dict['train_labels'])\n",
    "\n",
    "    score_dev = classifier.score(split_dict['feature_matrix_dev'], split_dict['dev_labels'])\n",
    "    return score_dev\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "split_count, vectorizer_count = split_data_get_feature_matrix(text, labels)\n",
    "gcv_count = grid_searchSVC(split_count['feature_matrix_train'], split_count['train_labels'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: With default C = 1 accuracy was [0.8578]\n",
      "DEV: With default C = 1 accuracy was [0.8584]\n"
     ]
    }
   ],
   "source": [
    "index = [gcv_count.cv_results_['params'].index({'C': 1})]\n",
    "score_train = gcv_count.cv_results_['mean_test_score'][index]\n",
    "score_dev = get_svm_results(split_count)\n",
    "\n",
    "print(f'TRAIN: With default C = 1 accuracy was {score_train}')\n",
    "print(f'DEV: With default C = 1 accuracy was {[score_dev]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: The best C parameter, based on gridsearch, was 0.01, with an accuracy of [0.8799]\n",
      "DEV: The best C parameter, based on gridsearch, was 0.01, with an accuracy of [0.8788]\n"
     ]
    }
   ],
   "source": [
    "best_C = gcv_count.best_params_['C']\n",
    "acc = gcv_count.best_score_\n",
    "score_dev = get_svm_results(split_count, c=best_C)\n",
    "print(f'TRAIN: The best C parameter, based on gridsearch, was {best_C}, with an accuracy of {[acc]}')\n",
    "print(f'DEV: The best C parameter, based on gridsearch, was {best_C}, with an accuracy of {[score_dev]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "split_Tfidf,vectorizer_Tfidf  = split_data_get_feature_matrix(text, labels, Vectorizer=TfidfVectorizer)\n",
    "gcv_Tfidf = grid_searchSVC(split_Tfidf['feature_matrix_train'], split_Tfidf['train_labels'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: With default C = 1 accuracy was [0.8852]\n",
      "DEV: With default C = 1 accuracy was [0.8924]\n"
     ]
    }
   ],
   "source": [
    "index = [gcv_Tfidf.cv_results_['params'].index({'C': 1})]\n",
    "score_train = gcv_Tfidf.cv_results_['mean_test_score'][index]\n",
    "score_dev = get_svm_results(split_Tfidf)\n",
    "print(f'TRAIN: With default C = 1 accuracy was {score_train}')\n",
    "print(f'DEV: With default C = 1 accuracy was {[score_dev]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: The best C parameter, based on gridsearch, was 0.1, with an accuracy of [0.88645]\n",
      "DEV: The best C parameter, based on gridsearch, was 0.1, with an accuracy of [0.8904]\n"
     ]
    }
   ],
   "source": [
    "best_C = gcv_Tfidf.best_params_['C']\n",
    "acc = gcv_Tfidf.best_score_\n",
    "score_dev = get_svm_results(split_Tfidf, c=best_C)\n",
    "print(f'TRAIN: The best C parameter, based on gridsearch, was {best_C}, with an accuracy of {[acc]}')\n",
    "print(f'DEV: The best C parameter, based on gridsearch, was {best_C}, with an accuracy of {[score_dev]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer:\n",
    "Comparing CountVectorizer with TfidfVectorizer shows that, generally, TfidfVectorizer performed _marginally_ better. \n",
    "\n",
    "Further, it was shown that using preliminary optimal C values TfidfVectorizer had an optimal C of 1 and CountVectorizer had an optimal C of 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Test different lengths of n-grams in the CountVectorizer on the IMDB data.Do you see any difference in the classification results or the optimal C value? Do these n-grams show up also in the list of most significant positive/negative features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_ranges(r):    \n",
    "    split_count, vectorizer_count = split_data_get_feature_matrix(text, labels, ngram_range=r)\n",
    "    gcv_count = grid_searchSVC(split_count['feature_matrix_train'], split_count['train_labels'])\n",
    "\n",
    "    index = [gcv_count.cv_results_['params'].index({'C': 1})]\n",
    "    score_train = gcv_count.cv_results_['mean_test_score'][index]\n",
    "    score_dev = get_svm_results(split_count)\n",
    "    print(f'RESULTS FOR NGRAM RANGE OF  {r}')\n",
    "    print('Using default parameters (C=1):')\n",
    "    print(f'(TRAIN) scores = {score_train}')\n",
    "    print(f'(DEV) scores = {[score_dev]}')\n",
    "\n",
    "    best_C = gcv_count.best_params_['C']\n",
    "    acc = gcv_count.best_score_\n",
    "    score_dev = get_svm_results(split_count, c=best_C)\n",
    "    print(f'TRAIN: The best C parameter, based on gridsearch, was {best_C}, with an accuracy of {[acc]}')\n",
    "    print(f'DEV: The best C parameter, based on gridsearch, was {best_C}, with an accuracy of {[score_dev]}')\n",
    "\n",
    "    results_dict= {'split_count': split_count,\n",
    "                    'vectorizer':vectorizer_count,\n",
    "                    'gcv':gcv_count, \n",
    "                    'score_train': score_train,\n",
    "                    'score_dev': score_dev,\n",
    "                    'best_C': best_C,\n",
    "                    'score_opt_train': acc,\n",
    "                    'score_opt_dev': score_dev}\n",
    "    print('\\n\\n')\n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS FOR NGRAM RANGE OF  (1, 1)\n",
      "Using default parameters (C=1):\n",
      "(TRAIN) scores = [0.8548]\n",
      "(DEV) scores = [0.8696]\n",
      "TRAIN: The best C parameter, based on gridsearch, was 0.01, with an accuracy of [0.8782]\n",
      "DEV: The best C parameter, based on gridsearch, was 0.01, with an accuracy of [0.889]\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS FOR NGRAM RANGE OF  (1, 2)\n",
      "Using default parameters (C=1):\n",
      "(TRAIN) scores = [0.8829]\n",
      "(DEV) scores = [0.8808]\n",
      "TRAIN: The best C parameter, based on gridsearch, was 0.01, with an accuracy of [0.89045]\n",
      "DEV: The best C parameter, based on gridsearch, was 0.01, with an accuracy of [0.8906]\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS FOR NGRAM RANGE OF  (1, 3)\n",
      "Using default parameters (C=1):\n",
      "(TRAIN) scores = [0.88325]\n",
      "(DEV) scores = [0.8904]\n",
      "TRAIN: The best C parameter, based on gridsearch, was 0.01, with an accuracy of [0.89055]\n",
      "DEV: The best C parameter, based on gridsearch, was 0.01, with an accuracy of [0.8964]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ngram_dict = {}\n",
    "ranges = [(1, 1),\n",
    "          (1, 2),\n",
    "          (1, 3)]\n",
    "for r in ranges:\n",
    "    ngram_dict[r] = test_ranges(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer (Part1):\n",
    "It seems that including bigrams (ngram=2) improves the performance, however, ngram=3 does not seem to add any additional improvements. Preliminary optimal C for all 3 were the same (C=0.01), however, one could (in principle) dive deeper and see if there are better optimal Cs and whether they deviate. For curiousity's sake I will test a few other ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS FOR NGRAM RANGE OF  (2, 2)\n",
      "Using default parameters (C=1):\n",
      "(TRAIN) scores = [0.86035]\n",
      "(DEV) scores = [0.8586]\n",
      "TRAIN: The best C parameter, based on gridsearch, was 0.01, with an accuracy of [0.87145]\n",
      "DEV: The best C parameter, based on gridsearch, was 0.01, with an accuracy of [0.8712]\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS FOR NGRAM RANGE OF  (2, 3)\n",
      "Using default parameters (C=1):\n",
      "(TRAIN) scores = [0.85865]\n",
      "(DEV) scores = [0.8556]\n",
      "TRAIN: The best C parameter, based on gridsearch, was 0.01, with an accuracy of [0.8686]\n",
      "DEV: The best C parameter, based on gridsearch, was 0.01, with an accuracy of [0.8696]\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS FOR NGRAM RANGE OF  (3, 3)\n",
      "Using default parameters (C=1):\n",
      "(TRAIN) scores = [0.8092]\n",
      "(DEV) scores = [0.8086]\n",
      "TRAIN: The best C parameter, based on gridsearch, was 0.01, with an accuracy of [0.82685]\n",
      "DEV: The best C parameter, based on gridsearch, was 0.01, with an accuracy of [0.8352]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ranges = [(2, 2),\n",
    "          (2, 3),\n",
    "          (3, 3)]\n",
    "for r in ranges:\n",
    "    ngram_dict[r] = test_ranges(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As one would expect, not including single words (i.e. ranges from 2 and upwards) did not improve performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_interpreter(ngram_dict_range):\n",
    "\n",
    "    vectorizer = ngram_dict_range['vectorizer']\n",
    "    gcv = ngram_dict_range['gcv']\n",
    "    \n",
    "    index2feature={}\n",
    "    for feature,idx in vectorizer.vocabulary_.items():\n",
    "        assert idx not in index2feature #This really should hold\n",
    "        index2feature[idx]=feature\n",
    "\n",
    "    indices=np.argsort(gcv.best_estimator_.coef_[0])\n",
    "    print(indices)\n",
    "    for idx in indices[:30]:\n",
    "        print(index2feature[idx])\n",
    "    print(\"-------------------------------\")\n",
    "    for idx in indices[::-1][:30]: #you can also do it the other way round, reverse, then pick\n",
    "        print(index2feature[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9898 12882 98243 ... 31886 61540 24846]\n",
      "awful\n",
      "boring\n",
      "worst\n",
      "poorly\n",
      "disappointing\n",
      "poor\n",
      "waste\n",
      "disappointment\n",
      "dull\n",
      "bad\n",
      "unfortunately\n",
      "terrible\n",
      "lacks\n",
      "mess\n",
      "the worst\n",
      "worse\n",
      "lame\n",
      "ridiculous\n",
      "laughable\n",
      "at best\n",
      "stupid\n",
      "not even\n",
      "oh\n",
      "the original\n",
      "avoid\n",
      "horrible\n",
      "fails\n",
      "annoying\n",
      "wonder\n",
      "not worth\n",
      "-------------------------------\n",
      "excellent\n",
      "perfect\n",
      "great\n",
      "superb\n",
      "today\n",
      "enjoyable\n",
      "amazing\n",
      "wonderful\n",
      "fantastic\n",
      "rare\n",
      "must see\n",
      "simple\n",
      "liked\n",
      "10 10\n",
      "enjoyed\n",
      "at the end\n",
      "loved\n",
      "definitely worth\n",
      "of what\n",
      "noir\n",
      "favorite\n",
      "brilliant\n",
      "fun\n",
      "wonderfully\n",
      "enjoyed it\n",
      "bit\n",
      "surprisingly\n",
      "love this\n",
      "well worth\n",
      "fascinating\n"
     ]
    }
   ],
   "source": [
    "feature_interpreter(ngram_dict[(1, 3)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer (Part2):\n",
    "As mentioned earlier including ngrams of 1 and 2 improved classifier performance and this is reflected in the classifier coefficients. \n",
    "\n",
    "For example 'definitely worth', 'enjoyed it' and 'must see' were flagged as important features for positive labels and 'the worst' and 'waste of' were considered flagged as important features for negative labels.\n",
    "\n",
    "Considering that ngrams of 3 did not further improve classerier performance is reflected in the observation that none of the word triplets were flagged as important when including them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.In the data package for the course (http://dl.turkunlp.org/intro-to-nlp.tar.gz),the directory language_identification contains data for 5 languages. Based on this data, train an SVMclassifier for language recognition between these 5 language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-02-26 03:54:20--  http://dl.turkunlp.org/intro-to-nlp.tar.gz\n",
      "Resolving dl.turkunlp.org (dl.turkunlp.org)... 195.148.30.23\n",
      "Connecting to dl.turkunlp.org (dl.turkunlp.org)|195.148.30.23|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 76192539 (73M) [application/octet-stream]\n",
      "Saving to: ‘intro-to-nlp.tar.gz’\n",
      "\n",
      "intro-to-nlp.tar.gz 100%[===================>]  72.66M   346MB/s    in 0.2s    \n",
      "\n",
      "2020-02-26 03:54:20 (346 MB/s) - ‘intro-to-nlp.tar.gz’ saved [76192539/76192539]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://dl.turkunlp.org/intro-to-nlp.tar.gz\n",
    "    \n",
    "import tarfile\n",
    "with tarfile.open('intro-to-nlp.tar.gz', 'r:gz') as t:\n",
    "    t.extractall()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "fnames = [f'intro-to-nlp/language-identification/{f}' for f in listdir('intro-to-nlp/language-identification/') if '.txt' in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "\n",
    "data_dict = {'train':[], 'test':[], 'devel': []}\n",
    "for file in fnames:\n",
    "    \n",
    "    with open(file, 'r') as f:\n",
    "        text = f.read().split('\\n')\n",
    "    \n",
    "    lang, sample = file.split('/')[-1].split('.')[0].split('_')\n",
    "    \n",
    "    for t in text:\n",
    "        data_dict[sample].append([t, lang])\n",
    "    \n",
    "#for key in data_dict:\n",
    "#    shuffle(data_dict[key])\n",
    "\n",
    "train = np.array(data_dict['train'])[:, 0]\n",
    "train_label = np.array(data_dict['train'])[:, 1]\n",
    "\n",
    "test = np.array(data_dict['test'])[:, 0]\n",
    "test_label = np.array(data_dict['test'])[:, 1]\n",
    "\n",
    "dev = np.array(data_dict['devel'])[:, 0]\n",
    "dev_label = np.array(data_dict['devel'])[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer=CountVectorizer(max_features=100000,\n",
    "                           binary=True,\n",
    "                           ngram_range=(1,1),\n",
    "                          analyzer='char')\n",
    "\n",
    "fm_train=vectorizer.fit_transform(train)\n",
    "fm_dev=vectorizer.transform(dev)\n",
    "fm_test=vectorizer.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_searchSVC_multiclass(X_train, y_train):\n",
    "    '''Have to use appropriate scoring for multiclass; I chose f1_macro\n",
    "    - I could have modified the earlier one but decided to leave this one here for easier reviewing \n",
    "    '''\n",
    "    from sklearn.svm import LinearSVC\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    \n",
    "    param_grid =  [{'C': [0.001, 0.01, 0.1, 1, 10, 120]}]   \n",
    "\n",
    "    grid_search = GridSearchCV(LinearSVC(), param_grid, cv=5, scoring='f1_micro') \n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "gcv_multi = grid_searchSVC_multiclass(fm_train, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.9066933066933067\n",
      "Best Params: {'C': 10}\n"
     ]
    }
   ],
   "source": [
    "print(f'Best Score: {gcv_multi.best_score_}')\n",
    "print(f'Best Params: {gcv_multi.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8999000999000999"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(gcv_multi.predict(fm_dev), dev_label, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9026973026973028"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(gcv_multi.predict(fm_test), test_label, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. If you completed (3),toy around with features, especially the ngram_range and analyzer parameters, which allow you to test classification based on character ngrams of various lengths (not only word n-grams). Gain some in sight in to the accuracy of the classifier with different features, and try to identify misclassified documents-why do you think they were misclassified?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def language_features(train, dev, test, ngram_range=(1, 1), analyzer='char'):\n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "    vectorizer=CountVectorizer(max_features=100000,\n",
    "                               binary=True,\n",
    "                               ngram_range=ngram_range,\n",
    "                              analyzer='char')\n",
    "\n",
    "    fm_train=vectorizer.fit_transform(train)\n",
    "    fm_dev=vectorizer.transform(dev)\n",
    "    fm_test=vectorizer.transform(test)\n",
    "    \n",
    "    return fm_train, fm_dev, fm_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For range (1, 1)\n",
      "Best Params: {'C': 10}\n",
      "Train Scores = 0.9066933066933067\n",
      "DEV scores = 0.9018543606721238\n",
      "TEST scores = 0.9020641434044983\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For range (1, 2)\n",
      "Best Params: {'C': 0.01}\n",
      "Train Scores = 0.9758241758241758\n",
      "DEV scores = 0.9728781264094792\n",
      "TEST scores = 0.9768701639528132\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For range (1, 3)\n",
      "Best Params: {'C': 0.01}\n",
      "Train Scores = 0.9778221778221778\n",
      "DEV scores = 0.9756938867058451\n",
      "TEST scores = 0.9798723820168679\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For range (2, 3)\n",
      "Best Params: {'C': 0.01}\n",
      "Train Scores = 0.9760239760239761\n",
      "DEV scores = 0.9737401355284158\n",
      "TEST scores = 0.975535589576533\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#maxRange = 6\n",
    "#ranges = []\n",
    "#for x in range(1, maxRange):\n",
    "#    for y in range(x, maxRange):\n",
    "#        ranges.append((x, y))\n",
    "\n",
    "ranges = [(1, 1), (1, 2),(2, 2), (1, 3), (2, 3)]\n",
    "\n",
    "for r in ranges:    \n",
    "    fm_train, fm_dev, fm_test = language_features(train, dev, test, ngram_range=r) \n",
    "    \n",
    "    gcv_multi = grid_searchSVC_multiclass(fm_train, train_label)\n",
    "        \n",
    "    score_dev = f1_score(gcv_multi.predict(fm_dev), dev_label, average='micro')\n",
    "    score_test = f1_score(gcv_multi.predict(fm_test), test_label, average='micro')\n",
    "\n",
    "    print(f'For range {r}')\n",
    "    print(f'Best Params: {gcv_multi.best_params_}')\n",
    "    print(f'Train Scores = {gcv_multi.best_score_}')\n",
    "    print(f'DEV scores = {score_dev}')\n",
    "    print(f'TEST scores = {score_test}')        \n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For range (2, 2)\n",
      "Best Params: {'C': 0.01}\n",
      "Train Scores = 0.9734265734265735\n",
      "DEV scores = 0.9692307692307692\n",
      "TEST scores = 0.9706293706293706\n",
      "\n"
     ]
    }
   ],
   "source": [
    "r = (2, 2)\n",
    "fm_train, fm_dev, fm_test = language_features(train, dev, test, ngram_range=r) \n",
    "    \n",
    "gcv_multi = grid_searchSVC_multiclass(fm_train, train_label)\n",
    "\n",
    "score_dev = f1_score(gcv_multi.predict(fm_dev), dev_label, average='micro')\n",
    "score_test = f1_score(gcv_multi.predict(fm_test), test_label, average='micro')\n",
    "\n",
    "print(f'For range {r}')\n",
    "print(f'Best Params: {gcv_multi.best_params_}')\n",
    "print(f'Train Scores = {gcv_multi.best_score_}')\n",
    "print(f'DEV scores = {score_dev}')\n",
    "print(f'TEST scores = {score_test}')        \n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For range (1, 2)\n",
      "Best Params: {'C': 0.01}\n",
      "Train Scores = 0.9758241758241758\n",
      "DEV scores = 0.974025974025974\n",
      "TEST scores = 0.9744255744255744\n",
      "\n"
     ]
    }
   ],
   "source": [
    "r = (1, 2)\n",
    "fm_train, fm_dev, fm_test = language_features(train, dev, test, ngram_range=r) \n",
    "    \n",
    "gcv_multi = grid_searchSVC_multiclass(fm_train, train_label)\n",
    "\n",
    "score_dev = f1_score(gcv_multi.predict(fm_dev), dev_label, average='micro')\n",
    "score_test = f1_score(gcv_multi.predict(fm_test), test_label, average='micro')\n",
    "\n",
    "print(f'For range {r}')\n",
    "print(f'Best Params: {gcv_multi.best_params_}')\n",
    "print(f'Train Scores = {gcv_multi.best_score_}')\n",
    "print(f'DEV scores = {score_dev}')\n",
    "print(f'TEST scores = {score_test}')        \n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = gcv_multi.predict(fm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pred==test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label: pt, predicted label: et\n",
      "Nada mais!\n",
      "\n",
      "True label: pt, predicted label: en\n",
      "Artes Plásticas\n",
      "\n",
      "True label: pt, predicted label: en\n",
      "The Washington Post\n",
      "\n",
      "True label: pt, predicted label: es\n",
      "Tudo, claro está, muito arborizado.\n",
      "\n",
      "True label: pt, predicted label: es\n",
      "E o volume de alumínio daria para fazer 275 mil latas de refrigerante.\n",
      "\n",
      "True label: pt, predicted label: en\n",
      "Com Jeff Goldblum, Alan Bates, Kathy Baker e Jean-Pierre Cassel\n",
      "\n",
      "True label: pt, predicted label: en\n",
      "Para melhor cantor, figuram José Carreras, Thomas Hampson, Ben Heppner, Sergei Leiferkus e Bryn Terfei.\n",
      "\n",
      "True label: pt, predicted label: et\n",
      "E ele gostava de Roosevelt e detestava os nazistas.\n",
      "\n",
      "True label: pt, predicted label: et\n",
      "MONTE ESTORIL\n",
      "\n",
      "True label: pt, predicted label: fi\n",
      "Fantasia infantil:\n",
      "\n",
      "True label: pt, predicted label: en\n",
      "Choque frontal\n",
      "\n",
      "True label: pt, predicted label: es\n",
      "LUIZ FELIPE DE ALENCASTRO, 48, historiador, é pesquisador de o Cebrap( Centro Brasileiro de Análise e Planejamento) e professor de o Instituto de Economia de a Unicamp( Universidade Estadual de Campinas).\n",
      "\n",
      "True label: pt, predicted label: es\n",
      "o 11, Primavera de 1963, homenageia Yves Klein).\n",
      "\n",
      "True label: pt, predicted label: et\n",
      "Um livro.\n",
      "\n",
      "True label: pt, predicted label: en\n",
      "?:? Jazz rap?\n",
      "\n",
      "True label: pt, predicted label: en\n",
      "Lírio\n",
      "\n",
      "True label: pt, predicted label: et\n",
      "Mas poderia vende- las.\n",
      "\n",
      "True label: pt, predicted label: et\n",
      "Dias 5 e 7, a as 18h00.\n",
      "\n",
      "True label: pt, predicted label: et\n",
      "Volta Galp a Portugal\n",
      "\n",
      "True label: pt, predicted label: es\n",
      "« La Saga del Traje Alienigena» tem a assinatura de Ron Frenz, Ruck Leonardi( desenho), Tom DeFalco e Roger Stern( argumento).\n",
      "\n",
      "True label: pt, predicted label: en\n",
      "Vereador renunciou\n",
      "\n",
      "True label: pt, predicted label: et\n",
      "A as 21h30.\n",
      "\n",
      "True label: pt, predicted label: en\n",
      "The Earth Works Group\n",
      "\n",
      "True label: pt, predicted label: en\n",
      "Campanha salarial\n",
      "\n",
      "True label: pt, predicted label: et\n",
      "Ônibus leve, US$ 55 mil, para o pesado, US$ 70 mil.\n",
      "\n",
      "True label: pt, predicted label: es\n",
      "Entre os denunciados por corrupção passiva estão o procurador de Justiça aposentado Aldegy do Nascimento, 26 delegados, inspetores e peritos de a Polícia Civil e Ary Chagas de Aguiar, assessor de a promotora Lúcia Atalla.\n",
      "\n",
      "True label: pt, predicted label: en\n",
      "\n",
      "\n",
      "True label: es, predicted label: en\n",
      "Hay informaciones que son opiniones y hay informaciones que son hechos.\n",
      "\n",
      "True label: es, predicted label: pt\n",
      "Ayudemos a mi compañero Jimmy\".\n",
      "\n",
      "True label: es, predicted label: en\n",
      "(\"¡ Vaya Bollo!\")\n",
      "\n",
      "True label: es, predicted label: pt\n",
      "¿ A qué esperáis para sorprender a papá?\n",
      "\n",
      "True label: es, predicted label: pt\n",
      "Ojala ubiese muchas empresas como esta.\n",
      "\n",
      "True label: es, predicted label: pt\n",
      "\" Mamá,¿ por qué nadie es como nosotros?\"\n",
      "\n",
      "True label: es, predicted label: et\n",
      "El Salmar, 5.\n",
      "\n",
      "True label: es, predicted label: pt\n",
      "Originalmente, Catania no había sido una zona típicamente mafiosa.\n",
      "\n",
      "True label: es, predicted label: en\n",
      "Pertch Proshian( 1839-1907);\n",
      "\n",
      "True label: es, predicted label: et\n",
      "Es Tauro.\n",
      "\n",
      "True label: es, predicted label: en\n",
      "Ursula K. Le Guin explora la sexualidad transespecies en The Left Hand of Darkness( 1969);\n",
      "\n",
      "True label: es, predicted label: pt\n",
      "¿ Instituciones o psicópatas?\n",
      "\n",
      "True label: es, predicted label: pt\n",
      "Ruiz Mateos,¿ héroe o villano?\n",
      "\n",
      "True label: es, predicted label: et\n",
      "Lleva por número KV 621.\n",
      "\n",
      "True label: es, predicted label: en\n",
      "Retablo mayor churrigueresco( s. XVIII).\n",
      "\n",
      "True label: es, predicted label: pt\n",
      "Es endémica de México.\n",
      "\n",
      "True label: es, predicted label: en\n",
      "* Edward S. Miller, War Plan Orange: The U.S. Strategy to Defeat Japan, 1897-1945, U.S. Naval Institute Press, 1991, ISBN: 0870217593\n",
      "\n",
      "True label: es, predicted label: en\n",
      "\n",
      "\n",
      "True label: fi, predicted label: et\n",
      "Lopulta oikeus tuomitsi heidät parituksesta- ei ihmiskaupasta.\n",
      "\n",
      "True label: fi, predicted label: et\n",
      "Maistele.\n",
      "\n",
      "True label: fi, predicted label: et\n",
      "\" 7 artikla\n",
      "\n",
      "True label: fi, predicted label: en\n",
      "1. JOHDANTO\n",
      "\n",
      "True label: fi, predicted label: et\n",
      "Uusi aamu\n",
      "\n",
      "True label: fi, predicted label: pt\n",
      "Arvosana: 3-\n",
      "\n",
      "True label: fi, predicted label: pt\n",
      "Quantumin auditorio\n",
      "\n",
      "True label: fi, predicted label: et\n",
      "MIES: Miksi?\n",
      "\n",
      "True label: fi, predicted label: en\n",
      "Jouduin töihin\n",
      "\n",
      "True label: fi, predicted label: et\n",
      "Viime vuonna.\n",
      "\n",
      "True label: fi, predicted label: en\n",
      "1. JOHDANTO\n",
      "\n",
      "True label: fi, predicted label: et\n",
      "Menen kauas\n",
      "\n",
      "True label: fi, predicted label: et\n",
      "Ole onnellinen.\n",
      "\n",
      "True label: fi, predicted label: et\n",
      "On aamu.\n",
      "\n",
      "True label: fi, predicted label: en\n",
      "Nyt se tapahtuu!\n",
      "\n",
      "True label: fi, predicted label: et\n",
      "Nuku nuku.\n",
      "\n",
      "True label: fi, predicted label: et\n",
      "Juho nousi ja asteli ovelle.\n",
      "\n",
      "True label: fi, predicted label: et\n",
      "Neil Diamond laulaa:\n",
      "\n",
      "True label: fi, predicted label: et\n",
      "Veikkausliigasta putosi FC KooTeePee ja liigaan nousi JJK.\n",
      "\n",
      "True label: fi, predicted label: et\n",
      "Kiinasta paljastui vale-Ikea\n",
      "\n",
      "True label: fi, predicted label: et\n",
      "Annamme anteeksi.\n",
      "\n",
      "True label: fi, predicted label: et\n",
      "Teema vaihtelee laidasta laitaan.\n",
      "\n",
      "True label: fi, predicted label: en\n",
      "It was worth it!\n",
      "\n",
      "True label: fi, predicted label: en\n",
      "Honduras\n",
      "\n",
      "True label: fi, predicted label: en\n",
      "Nam\n",
      "\n",
      "True label: fi, predicted label: et\n",
      "Foorumin avasi professori Kari Lukka.\n",
      "\n",
      "True label: fi, predicted label: en\n",
      "Lisää tietoa http://thrilltheworld09finland.blogspot.com/\n",
      "\n",
      "True label: fi, predicted label: et\n",
      "Te Rauparaha(~1760- 1849) oli Ngāti Toa maoriheimon johtaja.\n",
      "\n",
      "True label: fi, predicted label: en\n",
      "Mur!\n",
      "\n",
      "True label: fi, predicted label: en\n",
      "Bruxelles\n",
      "\n",
      "True label: fi, predicted label: en\n",
      "Johan nyt on perhana!\n",
      "\n",
      "True label: fi, predicted label: et\n",
      "Eivät.\n",
      "\n",
      "True label: fi, predicted label: et\n",
      "Mones.\n",
      "\n",
      "True label: fi, predicted label: et\n",
      "Mittaus oli nopeaa.\n",
      "\n",
      "True label: fi, predicted label: et\n",
      "Ja ne kyyneleet!\n",
      "\n",
      "True label: fi, predicted label: et\n",
      "Tulevatko he Porvoosta?\n",
      "\n",
      "True label: fi, predicted label: en\n",
      "\n",
      "\n",
      "True label: en, predicted label: et\n",
      "Huskers drool over Sooners.\n",
      "\n",
      "True label: en, predicted label: et\n",
      "E.g.\n",
      "\n",
      "True label: en, predicted label: es\n",
      "Lara Leibman@ENRON COMMUNICATIONS\n",
      "\n",
      "True label: en, predicted label: pt\n",
      "Get-A-Free-House.com\n",
      "\n",
      "True label: en, predicted label: et\n",
      "Let me know.\n",
      "\n",
      "True label: en, predicted label: et\n",
      "Kim.\n",
      "\n",
      "True label: en, predicted label: et\n",
      "Ok--fine.\n",
      "\n",
      "True label: en, predicted label: fi\n",
      "Question Mark\n",
      "\n",
      "True label: en, predicted label: et\n",
      "Selah.\n",
      "\n",
      "True label: en, predicted label: et\n",
      "-Juggernaut>\n",
      "\n",
      "True label: en, predicted label: es\n",
      "Ernie Simien\n",
      "\n",
      "True label: en, predicted label: fi\n",
      "Justin\n",
      "\n",
      "True label: en, predicted label: es\n",
      "Chris Enron Canada Corp. Suite 1100, 70 York Street Toronto, Ontario M5J 1S9 416-865-3700\n",
      "\n",
      "True label: en, predicted label: es\n",
      "Rhonda L Denton\n",
      "\n",
      "True label: en, predicted label: pt\n",
      "Is Fujairah a nice place to live in?\n",
      "\n",
      "True label: en, predicted label: pt\n",
      "Sara\n",
      "\n",
      "True label: en, predicted label: et\n",
      "Regards.\n",
      "\n",
      "True label: en, predicted label: es\n",
      "Electricity Market Design Conference March 25-26, 2002, Atlanta, Georgia\n",
      "\n",
      "True label: en, predicted label: et\n",
      "Sigh.\n",
      "\n",
      "True label: en, predicted label: et\n",
      "Kind regards.\n",
      "\n",
      "True label: en, predicted label: et\n",
      "OK.\n",
      "\n",
      "True label: en, predicted label: et\n",
      "It is like a mini tablet itself!\n",
      "\n",
      "True label: en, predicted label: et\n",
      "Big deal kinda stuff.\n",
      "\n",
      "True label: en, predicted label: et\n",
      "Fistfights, please.\n",
      "\n",
      "True label: en, predicted label: pt\n",
      "Jamaica\n",
      "\n",
      "True label: en, predicted label: pt\n",
      "Orr's a nightmare!\n",
      "\n",
      "True label: et, predicted label: es\n",
      "Campanada 1995.\n",
      "\n",
      "True label: et, predicted label: en\n",
      "1.2.3.\n",
      "\n",
      "True label: et, predicted label: fi\n",
      "Sotsiaal-klassiline hoiak\n",
      "\n",
      "True label: et, predicted label: fi\n",
      "Ain Kallis\n",
      "\n",
      "True label: et, predicted label: en\n",
      "SMITH KLINE 31,6\n",
      "\n",
      "True label: et, predicted label: en\n",
      "Sherry kodumaa.\n",
      "\n",
      "True label: et, predicted label: en\n",
      "( Antes Edition)\n",
      "\n",
      "True label: et, predicted label: en\n",
      "( naer)\n",
      "\n",
      "True label: et, predicted label: fi\n",
      "Igatsen selle järele tänapäevani.”\n",
      "\n",
      "True label: et, predicted label: en\n",
      "MART JUUR\n",
      "\n",
      "True label: et, predicted label: fi\n",
      "Valasin vett mööda renni.\n",
      "\n",
      "True label: et, predicted label: en\n",
      "ANDRES KLEMET\n",
      "\n",
      "True label: et, predicted label: fi\n",
      "Loe ka juhtkirja\n",
      "\n",
      "True label: et, predicted label: en\n",
      "Foto: Priit Simson\n",
      "\n",
      "True label: et, predicted label: fi\n",
      "Torman kööki.\n",
      "\n",
      "True label: et, predicted label: en\n",
      "Persses?\n",
      "\n",
      "True label: et, predicted label: en\n",
      "Bill Frisell\n",
      "\n",
      "True label: et, predicted label: fi\n",
      "Pensionini veel tosin aastat.\n",
      "\n",
      "True label: et, predicted label: fi\n",
      "Kasvatan viit hane.\n",
      "\n",
      "True label: et, predicted label: en\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "compare, lengths,  = [], [] \n",
    "langs_Y = []\n",
    "langs_y = []\n",
    "for x, y, z in zip(pred[a==False], test_label[a==False], test[a==False]):\n",
    "    compare.append(\"{} vs {} errors\".format(*sorted([x, y])))\n",
    "    lengths.append(len(z))\n",
    "    langs_Y.append(y)\n",
    "    langs_y.append(x)\n",
    "    print(f\"True label: {y}, predicted label: {x}\")\n",
    "    print(f\"{z}\")\n",
    "    print()\n",
    "tot_lengths = [len(x) for x in test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By eye-balling some of the wrongly predicted labels:\n",
    "\n",
    "Some of the incorrectly predicted labels are a bit disappointing. However some are understandable. The Washington Post is the name of a newspaper and had the label for Portugues, but English was predicted. The same when using actor names in portuguese and predicting English etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'et vs pt errors': 9,\n",
       "         'en vs pt errors': 16,\n",
       "         'es vs pt errors': 14,\n",
       "         'fi vs pt errors': 3,\n",
       "         'en vs es errors': 12,\n",
       "         'es vs et errors': 4,\n",
       "         'et vs fi errors': 31,\n",
       "         'en vs fi errors': 14,\n",
       "         'en vs et errors': 25})"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orignal label count\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({'pt': 27, 'es': 18, 'fi': 37, 'en': 26, 'et': 20})"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('orignal label count')\n",
    "Counter(langs_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "False label count\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({'et': 49, 'en': 41, 'es': 12, 'fi': 11, 'pt': 15})"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print()\n",
    "print('False label count')\n",
    "Counter(langs_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that English, Finnish and Estonian were often involved in mislabelling. It seems that when it comes to Finnish and Estonian there were frequent mislabelling associated between the two. As for English the language was involved in many errors but the trend seems to be more wide spread among the languages. \n",
    "\n",
    "Which makes sense linguistically, although I would have thought Spanish and Portuguese would have been mixed up more frequently. \n",
    "\n",
    "Finnish and Estonian have certain unique orthographical properties (double vowels 'aa' for example, lower frequency use of 'd', 'g', 'c' etc). English has historically been influenced many languages and Estonian and Finnish are a bit different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f62f111ff98>"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD4CAYAAADo30HgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3de3RV9Z338ff3nJMLuV8It3AJCIqo9YZoO/YmVbG1Yld1xLGtM+OqndW6nOk8M33oPFOn43TmGafz1KlTp09t1SpPLTrM2KaVSi9ab22R4A0QKBEQEsQEEhJCCMk55/v8cXbgnHCSnJAbHD6vtc7K3r/92/v8NpuVT377ty/m7oiIiPQKjXcDRETk5KJgEBGRFAoGERFJoWAQEZEUCgYREUkRGe8GDMXEiRO9pqZmvJshInJKWb9+/T53r8q0/ikVDDU1NdTV1Y13M0RETilm9vZQ6utUkoiIpFAwiIhICgWDiIikUDCIiEgKBYOIiKRQMIiISAoFg4iIpFAwiIhICgWDiIikUDBkoP3RWtofrR3vZoiIjAkFg4iIpMgoGMxsiZltNbN6M1ueZnmemT0eLF9rZjV9ls80sw4z+6tMtykiIuNj0GAwszBwP3ANsAC42cwW9Kl2G9Dq7nOBe4F7+iz/BvCzIW5TRETGQSY9hkVAvbtvd/duYCWwtE+dpcAjwfQqYLGZGYCZXQ/sADYNcZsiIjIOMgmGamB30nxDUJa2jrtHgTag0syKgP8J/P0JbBMAM7vdzOrMrK65uTmD5oqIyHCM9uDzV4F73b3jRDfg7g+4+0J3X1hVlfF7JkRE5ARl8qKeRmBG0vz0oCxdnQYziwClwH7gUuAGM/sXoAyIm1kXsD6DbYqIyDjIJBjWAfPMbDaJX97LgD/qU6cWuBX4LXAD8Iy7O/D+3gpm9lWgw92/FYTHYNsUEZFxMGgwuHvUzO4A1gBh4CF332RmdwN17l4LPAisMLN6oIXEL/ohb3OY+yIiIiMgo3c+u/tqYHWfsruSpruAGwfZxlcH26aIiIw/3fksIiIpFAwiIpJCwSAiIikUDCIikkLBICIiKRQMIiKSQsEgIiIpFAwiIpJCwSAiIikUDCIikkLBICIiKRQMIiKSQsEgIiIpFAwiIpJCwSAiIikUDCIikiKjYDCzJWa21czqzWx5muV5ZvZ4sHytmdUE5YvM7LXg87qZfSJpnZ1mtiFYVjdSOyQiIsMz6BvczCwM3A9cCTQA68ys1t3fTKp2G9Dq7nPNbBlwD3ATsBFYGLzKcyrwupn9xN2jwXofdvd9I7lDIiIyPJn0GBYB9e6+3d27gZXA0j51lgKPBNOrgMVmZu7emRQC+YCPRKNFRGT0ZBIM1cDupPmGoCxtnSAI2oBKADO71Mw2ARuAP0sKCgd+bmbrzez2/r7czG43szozq2tubs5kn0REZBhGffDZ3de6+znAJcCXzSw/WHS5u18EXAN8wcw+0M/6D7j7QndfWFVVNdrNFRE57WUSDI3AjKT56UFZ2jpmFgFKgf3JFdx9M9ABnBvMNwY/m4AnSZyyEhGRcZZJMKwD5pnZbDPLBZYBtX3q1AK3BtM3AM+4uwfrRADMbBYwH9hpZoVmVhyUFwJXkRioFhGRcTboVUnBFUV3AGuAMPCQu28ys7uBOnevBR4EVphZPdBCIjwALgeWm1kPEAc+7+77zGwO8KSZ9bbhMXd/eqR3TkREhm7QYABw99XA6j5ldyVNdwE3pllvBbAiTfl24PyhNlZEREaf7nwWEZEUCgYREUmhYBARkRQKBhERSaFgEBGRFAoGERFJoWAQEZEUCgYREUmhYBARkRQKBhERSaFgEBGRFAoGERFJoWAQEZEUCgYREUmhYBARkRQKBhERSZFRMJjZEjPbamb1ZrY8zfI8M3s8WL7WzGqC8kVm9lrwed3MPpHpNkVEZHwMGgxmFgbuB64BFgA3m9mCPtVuA1rdfS5wL3BPUL4RWOjuFwBLgO+YWSTDbYqIyDjIpMewCKh39+3u3g2sBJb2qbMUeCSYXgUsNjNz9053jwbl+YAPYZsiIjIOMgmGamB30nxDUJa2ThAEbUAlgJldamabgA3AnwXLM9kmwfq3m1mdmdU1Nzdn0FwRERmOUR98dve17n4OcAnwZTPLH+L6D7j7QndfWFVVNTqNFBGRozIJhkZgRtL89KAsbR0ziwClwP7kCu6+GegAzs1wmyIiMg4yCYZ1wDwzm21mucAyoLZPnVrg1mD6BuAZd/dgnQiAmc0C5gM7M9ymiIiMg8hgFdw9amZ3AGuAMPCQu28ys7uBOnevBR4EVphZPdBC4hc9wOXAcjPrAeLA5919H0C6bY7wvomIyAkYNBgA3H01sLpP2V1J013AjWnWWwGsyHSbIiIy/nTns4iIpFAwiIhICgWDiIikUDCIiEgKBYOIiKRQMIiISAoFg4iIpFAwiIhICgWDiIikUDCIiEgKBYOIiKRQMIiISAoFg4iIpFAwiIhICgWDiIikUDCIiEiKjILBzJaY2VYzqzez5WmW55nZ48HytWZWE5RfaWbrzWxD8POKpHV+HWzzteAzaaR2arS0P1pL+6N6A6mIZLdB3+BmZmHgfuBKoAFYZ2a17v5mUrXbgFZ3n2tmy4B7gJuAfcDH3X2PmZ1L4lWe1Unr3eLudSO0LyIiMgIy6TEsAurdfbu7dwMrgaV96iwFHgmmVwGLzczc/VV33xOUbwImmFneSDRcRERGRybBUA3sTppvIPWv/pQ67h4F2oDKPnU+Cbzi7keSyh4OTiN9xcxsSC0XEZFRMSaDz2Z2DonTS59LKr7F3c8D3h98Pt3PurebWZ2Z1TU3N49+Y0VETnOZBEMjMCNpfnpQlraOmUWAUmB/MD8deBL4jLu/1buCuzcGPw8Cj5E4ZXUcd3/A3Re6+8KqqqpM9klERIYhk2BYB8wzs9lmlgssA/pemlML3BpM3wA84+5uZmXAU8Byd3+pt7KZRcxsYjCdA1wLbBzeroiIyEgYNBiCMYM7SFxRtBl4wt03mdndZnZdUO1BoNLM6oG/BHovab0DmAvc1eey1DxgjZm9AbxGosfx3ZHcMREROTGDXq4K4O6rgdV9yu5Kmu4Cbkyz3teAr/Wz2Yszb6aIiIwV3fksIiIpFAwiIpJCwSAiIikUDCIikkLBICIiKRQMIiKSQsEgIiIpFAwiIpJCwSAiIikUDCIikkLBICIiKRQMIiKSQsGQgfjhLtofe4pDv/wtHo+Pd3NEREZVRk9XPd11b6rnyPo3AciZPX2cWyMiMrrUY8hAz/ZjL6yL7uz78joRkeyiHkMGerbvJnfBGcT2H6Bnh4JBRLKbegyDiO1rJdbcSs7sanJmTaNn5x6NM4hIVssoGMxsiZltNbN6M1ueZnmemT0eLF9rZjVB+ZVmtt7MNgQ/r0ha5+KgvN7M7jMzG6mdGkk92xsACE+tIjJzCn64i9g7zePcKhGR0TNoMJhZGLgfuAZYANxsZgv6VLsNaHX3ucC9wD1B+T7g4+5+HnArsCJpnW8DnwXmBZ8lw9iPUdPT8C4A4fISwhVlibK33xnPJomIjKpMegyLgHp33+7u3cBKYGmfOkuBR4LpVcBiMzN3f9Xd9wTlm4AJQe9iKlDi7r9zdwceBa4f9t6MgujuvUAiGEIVpQD07FIwiEj2yiQYqoHdSfMNQVnaOu4eBdqAyj51Pgm84u5HgvoNg2wTADO73czqzKyuuXnsT+FEG9/FCvKxvFzC5cVgEFUwiEgWG5PBZzM7h8Tppc8NdV13f8DdF7r7wqqqqpFv3CCiu/cSLi8BwCIRQiXFOpUkIlktk2BoBGYkzU8PytLWMbMIUArsD+anA08Cn3H3t5LqJ98plm6b46790VqObKwnVFZytCxcWaoeg4hktUyCYR0wz8xmm1kusAyo7VOnlsTgMsANwDPu7mZWBjwFLHf3l3oru/s7QLuZXRZcjfQZ4MfD3JcR5+7EW9sIVxwLhlBFqcYYRCSrDRoMwZjBHcAaYDPwhLtvMrO7zey6oNqDQKWZ1QN/CfRe0noHMBe4y8xeCz6TgmWfB74H1ANvAT8bqZ0aKX6kGz/SQ6i0+GhZuLyE2DvNeDQ6ji0TERk9Gd357O6rgdV9yu5Kmu4Cbkyz3teAr/WzzTrg3KE0dqx5RycAoeLCo2WhkkJwJ7bvAJEpE8eraSIio0Z3Pg8gfjAIhqKCo2Wh4iIAYu/uH5c2iYiMNgXDAOJBj8GSg6Ek0XuIvrtvXNokIjLaFAwD6A2GlB5DiXoMIpLdFAwDOBYME46W9Y43RBUMIpKlFAwD8I5OLD8Pixwbo7dImFBFqXoMIpK1FAwDiHd0ppxG6hWZXEl0r4JBRLKTgmEA8Y7OlIHnXuHJleoxiEjWUjAMIN7RSag4TTBMqiTWpGAQkeykYBhAvKOTUOGE48ojk8qJ7TtA4onhIiLZRcHQD4/H8UOH044xhCeWJx6XEVy1JCKSTRQM/Yh3dII7VpB/3LJwVTkAsebWsW6WiMioUzD0I97SDkBowvGnksITE8EQbW4Z0zaJiIwFBUM/YgcSwWCFaXoMQTDE9h0Y0zaJiIwFBUM/4i1tAITSnUqaVAFAbJ9OJYlI9lEw9CN24CAAVpDmVFJFaaKOgkFEspCCoR/x1mCMIU2PwXJzCJUVE2tSMIhI9skoGMxsiZltNbN6M1ueZnmemT0eLF9rZjVBeaWZPWtmHWb2rT7r/DrYZt83u50UYq2JU0nprkoCCFdVqMcgIllp0De4mVkYuB+4EmgA1plZrbu/mVTtNqDV3eea2TLgHuAmoAv4Cok3taV7W9stwZvcTjrx1oNYfi4WDqddHp5YRkxXJYlIFsqkx7AIqHf37e7eDawElvapsxR4JJheBSw2M3P3Q+7+IomAOKXEWtvSji/0Ck8sJ7ZfVyWJSPbJJBiqgd1J8w1BWdo67h4F2oDKDLb9cHAa6StmZukqmNntZlZnZnXNzc0ZbHJkxFvb044v9ApPLNPlqiKSlcZz8PkWdz8PeH/w+XS6Su7+gLsvdPeFVVVVY9a42IGD/Y4vQKLHEG9tx6PRMWuTiMhYyCQYGoEZSfPTg7K0dcwsApQCAz5+1N0bg58HgcdInLI6acRb2ggNcioJd2LBHdIiItkik2BYB8wzs9lmlgssA2r71KkFbg2mbwCe8QEePWpmETObGEznANcCG4fa+NEUaxukx1BZlqinK5NEJMsMelWSu0fN7A5gDRAGHnL3TWZ2N1Dn7rXAg8AKM6sHWkiEBwBmthMoAXLN7HrgKuBtYE0QCmHgl8B3R3TPhsHdiR/oIDRh4DEGUDCISPYZNBgA3H01sLpP2V1J013Ajf2sW9PPZi/OrIljzzs6IRbDJuT1W+foE1Z1ZZKIZBnd+ZzGQI/D6HX0VFKzgkFEsouCIY14EAyhgv57DKHyEgiFdCpJRLJORqeSTjdHH7ndzxhD+6OJsXcrzFcwiEjWUY8hjWM9hv4HnwFCRQUKBhHJOgqGNOKD9Bh6hYoK9HpPEck6CoY0Yhn3GArVYxCRrKNgSCN+4CDkRCA3Z8B6oeICvZNBRLKOgiGN+IGDhMuK6ee5fkeFigrxzsPEDx0eo5aJiIw+BUMasQMHCZWVDFovVFyQqK/TSSKSRRQMacTbDhIqKx60nhUFwaABaBHJIgqGNGKt7YQzCIZQcWGivt7kJiJZRMGQRqY9hpB6DCKShRQMacRbDxLOZIxBwSAiWUjB0IdHo8TbOxLPQhqE5UQIlRQRbdKpJBHJHgqGPuJtHQCESgc/lQQQnlxJ7N0BX1YnInJKUTD00XvXc7g882CINikYRCR7ZBQMZrbEzLaaWb2ZLU+zPM/MHg+WrzWzmqC80syeNbMOM/tWn3UuNrMNwTr32WB3k42R3uckZXIfA0BkinoMIpJdBg0GMwsD9wPXAAuAm81sQZ9qtwGt7j4XuBe4JyjvAr4C/FWaTX8b+CwwL/gsOZEdGGmx1qDHkMFVSXDsVNIAr7gWETmlZNJjWATUu/t2d+8GVgJL+9RZCjwSTK8CFpuZufshd3+RREAcZWZTgRJ3/50nfqM+Clw/nB0ZKfG24AF6GQw+A0QmV+JHuo+OTYiInOoyCYZqYHfSfENQlraOu0eBNqBykG02DLJNAMzsdjOrM7O65ubmDJo7PPHWxKmkzHsMEwGIvbtv1NokIjKWTvrBZ3d/wN0XuvvCqqqqUf++3re3ZXpVUmRyIv+iGmcQkSyRSTA0AjOS5qcHZWnrmFkEKAUG+k3ZGGxnoG2Oi/iBg1hRAZaT2VtPw1MSwRDbqx6DiGSHTIJhHTDPzGabWS6wDKjtU6cWuDWYvgF4xgcYjXX3d4B2M7ssuBrpM8CPh9z6URBrPZjxaSSASHAqKbpXPQYRyQ6D/lns7lEzuwNYA4SBh9x9k5ndDdS5ey3wILDCzOqBFhLhAYCZ7QRKgFwzux64yt3fBD4PfB+YAPws+Iy7eMsBQhWlGdcPFRUk7n7e0zSKrRIRGTsZnS9x99XA6j5ldyVNdwE39rNuTT/ldcC5mTZ0rMRa2wkPIRgAItWTFAwikjVO+sHnsRbb3zb0YJg2iWijgkFEsoOCoY94a1vG9zD0ilRPItr47ii1SERkbCkYkng0Srytg3Bl2ZDWi1RPJr6/jfjhI6PUMhGRsaNgSHL0cRhD6DG0P1pLz87EvXoaZxCRbKBgSBJvOQBAqHJoYwy9D9xTMIhINlAwJIm1BI/DKB9aMPTe9xDdvXfE2yQiMtYUDEliLW0AQ74qKVReAuEwPTv3jEazRETGlIIhSTwIhqHc4AZg4TCRGZOJ7jwpnuohIjIsCoYkJ9pjAMipqaZnh4JBRE59CoYksZY2LD+XUEH+kNfNmV1Nj3oMIpIFFAxJYs0thKsqTmjdnNnVxA8cJBa8zwGgqydGU3sXsbje7iYip47Mni19mog1txKuKj+hdXNqqnHgJ89v5T+2d9LYephD3TEA8iIhZlQUMLOigNkTC/nrq88iPyc8gi0XERk5CoYkseYWItOnnNC6j7WE+PlVN7Lut01MLc3nghllFOZFyMsJ09Texa6WTp7d0sQzwIrfvc3FM8u55rwpfOLCaorzc0Z2R0REhkHBkCTW1ErehWcPeb3fdsA9DW3kTp7Opzr3cNbSqwiH7Lh6XT0x3t5/iNxIiBe27eOuH2/in3+2hesvrOZzH5jDrMrCkdgNEZFhUTAEPBYjtv/AkMcY3jwMX2wIMbEoj//94o8omZDD1tDVaevm54Q5a0riLunZE4toaO1k7fYWnli3m5+8todv3HQBVy6YPOx9EREZDgVDINbSDvE4kSGMMTR0wxd2hSgNw63vq2HC6xMpeG1jxutPLy9g+sUFLD57Ej9Yu4vPPlrHFfMnccX8SYQs0eP4o0tnDnlfRESGI6OrksxsiZltNbN6M1ueZnmemT0eLF9rZjVJy74clG81s6uTynea2QYze83M6kZiZ4Yj1twCMGiPYVWrsarVWLHf+PSOEIficH2pUzIhh86aGeS2tBI+2DGk7y4ryOX2D8zhopnlPLOliZUv79KVTCIybgYNBjMLA/cD1wALgJvNbEGfarcBre4+F7gXuCdYdwGJ13yeAywB/iPYXq8Pu/sF7r5w2HsyTLHmVoCMr0r61UGjNQbLKpyqYOy4c84sAIq2bR/y9+eEQ3zyomquOXcKG/e089+vNBDv/7XZIiKjJpMewyKg3t23u3s3sBJY2qfOUuCRYHoVsNjMLChf6e5H3H0HUB9s76RztMcwafAxhj098EonXFIIM3OPlR86cw4eMoo2bzuhNpgZ759XxUfOnsyruw/wk9f34AoHERljmQRDNbA7ab4hKEtbx92jQBtQOci6DvzczNab2e1Db/rIijVlFgzu8HSbURiCDxal/tKOFRTQOWsGxZt/P6y2fPisKt4/byJrd7Twz09vUTiIyJgaz8Hny9290cwmAb8wsy3u/nzfSkFo3A4wc+boDcRGG5uwggmESooGrLfhMDT0GNeVxslPE6sdZ5/JxGdfhFgMwid2E5uZseScKXRH43znue2EzPjS1WdhdvwlsCIiIy2THkMjMCNpfnpQlraOmUWAUmD/QOu6e+/PJuBJ+jnF5O4PuPtCd19YVVWVQXNPTHRPE5HqSQP+8u2IwS8PGtNynPMnpK/Tft7ZhA93UbSlfljtMTM+fv40brl0Jt/+9Vv8y5qt6jmIyJjIJBjWAfPMbLaZ5ZIYTK7tU6cWuDWYvgF4xhO/xWqBZcFVS7OBecDLZlZoZsUAZlYIXAVkfp3nKOgNhoH8sMXoiBvXlDj95Ufbxe8hHglTvnb9sNsUMuMflp57NBz+afVm4rpaSURG2aCnktw9amZ3AGuAMPCQu28ys7uBOnevBR4EVphZPdBCIjwI6j0BvAlEgS+4e8zMJgNPBn+dR4DH3P3pUdi/jEUbmyiYP6ff5T0Oj7cac3Kd6tx+qxErKKD9vAWUr32F3X9yM/0mSIZCoUQ4RELGd1/YwY59h7j3pgv0GA0RGTUZjTG4+2pgdZ+yu5Kmu4Ab+1n3H4F/7FO2HTh/qI0dLd7dQ6ypZcAewy/ajaaocUV5PO3yrt+9DkD+ZefTcvmlzPn371G0+fd0LDhrWG17bO0uAM6cXMzHz5/GU2/s4Yp/fY6Vn7uMM6oGHg8RETkReuw2EN27D9yJTO1/DOOxFmNWrjMvb/Dt7f/ge4kWTGDyU78YsTaaGe+dU8mfXj6bQ91Rrvv3F3ls7S6NO4jIiFMwkDiNBPTbY9hwGN44bNxc0f/YQrJ4fj7NV36IyhfWkt8wsu+BnjOxiDs+PJfzZ5TxN09u4NaH1/FO2+ER/Q4ROb0pGIBow14AItPTP8DuB/uNwpBzXWnmf53vufHjxPNymfnwD0ekjcnKCnL5f7ddyt1Lz2Hdjhau+sbzfO+F7fTE0p/mEhEZCgUD0LO9AUIhcmZNSylf1Wo8vM94ut04Nx+ebs98IDlaVkrjTddTvvYVKl5cO9JNZuW63URCIT7/oTOYUprP157azEe/+QIv1e8b8e8SkdOLnq4K9NTvIjJzCpZ3/OVGdZ1GHLikMLPeQu8gNMCOadMpmzqFmm8+wL7OHrpLioHEAPVIqSzK44/fV8Pmdw7y1IY93PK9tZw5uYirFkxhWlniZgs9oVVEhkI9BqD7rd3kzJlxXHnUE89EmpcHFScSoaEQW66/llA0xvwfPwXx0TnVY2YsmFbCX3zkTK45dwq7Ww7zrWfr+eHLu2g62DUq3yki2eu0DwZ3p+etBnLnHv9X9eYuOBS3jHsL6RyurGDb1R+h/O1dzPzNyJ9SSpYTDvH+eVX89dVn8eGzqti69yDf/OU2/vKJ19i1v3NUv1tEssdpfyoptncf3nmYnDOO7zG8fMioCDtnDHBDWybePf9cKrZvZ9bzL9E6p4aeUb6FIz8nzJULpvDeMyby/O+beeqNd6h9bQ9/eMkM7rxiHlNK80f1+0Xk1Hba9xi6t+4EIGduajC80XCAxp5Eb2HYz64zY9s1V9NdVMj8H/2UUNfYnN4pyovw0fOm8vyXPszNi2byn3W7+eDXn+Ufn3qTlkPdY9IGETn1nPbBcOTVzQDknZ96h/Ijv3mbHOv/YXlDFZ2Qz5brPsaEllZmPbDiaHnX715PGbAeDb/a3MTZU0v488Vncs60Er73wg7ef88zfOPnW2nv6hnV7xaRU89pHwxdr24m54wZhEuLj5bt7zjCT97Yw/kTSPto7RPVVjOT3e+7jEk//zWVz740chvOUEVhLjdcPIM7F8/jA2dWcd8z9XzgX57l3375e1rVgxCRwGk/xnDklc1M+MDFKWWP/PZtuqNxLikb+cdN7PzgH1DW1srsbz1I1/SpjMc1Q5NL8vnilWeysbGNe3/xe/7tl9v4znPbuemSGXzqslnMnaRnMImczk7rHkPP7r3E3t1P3gVnHy3btb+T7zz3Fh89b8rRdzmPJA+HqV9+J9HSYs766tcpaGoe+S/JwGNrd/FGQxuLz57MnYvnMX9KMY/+dicf+cZzfOy+F3jg+bfYue+QnsUkcho6rYOh8+e/AaDgisQ7gtydu2o3EgkZd117zqh9b095GVv+YTkeDnPBo49RUf/WqH1XJqaU5HPjwhl8acl87rp2AZFwiH9avYUP/euv+cDXn+VvntzAzza8w4FOnW4SOR2c1qeSDv3sBXLmzTp6D8PTG/fy663N/O3Hzh71Szq7qqey6et/x7y/+SfOW/lfNDc3sfvTf0jPxIHfOT2aSoJ3PNy0cAZXnj2Z3797kG3vHmTV+gYeW7sLMzhnWgnvnVPJJTUVXFJTQXnhMK/lFZGTzmkbDNE9TRx+6VXKPr8MgI4jUf7+J29y9tQS/vh9NWPShu7JVbzyJ5+i5vmXmP7cb6h8/nfsPe8cGhdeSOekquMenZHu6qWRerxG8vskIDFQfUFTAxcY5HzsPTS0dlLf3MFbTYd4+KWdfPeFHQDUVBZw9tQS5k8pYd7kImZWFDCzsuBoyIjIqee0DYbW+34AQMkfX097Vw9/9cTr7G3v4v5bLiISHrszbB6JsOOKD9Lyp8uY9sSPmfKrF5j2ymt0VE2k4/WL6Jo2hXhODuEjR/At2wlFo8RzcjhcXkbbzONvyhsN4ZAxq7KQWZWFLJ4PPbE4ja2H2bn/EI0HDvPyjhae3riX5NGI0gk5VJdNYFrZBKaX934KmFGR+Fk6QcEhcrLKKBjMbAnwTRKv9vyeu/9zn+V5wKPAxcB+4CZ33xks+zJwGxAD7nT3NZlsczQdfvEV2r//Y4r/6KNs9DzuvO8F9hzo4m8/djYXzyofq2akODJlEjvu/Czbzj2XyRs3U7l1G1U/f47wkSMp9eLhMKFY7Oh8x8/WsO/DlydeDlRWOvQvjscp2LmLypfrKG58h6IfPkFOywFCPT3EzDhSUkLXyy/TMX8e7e9ZwJHJVeSEQ9RMLKRmYuGx9kdj7O/opuVQ4tPa2c2Bzh42NrbxwrZmjkRTnxOVnxOivCCX+VOKmVySz6TiPMoKcimdkEPphByK8iMU5kYoyAszISdMQW6YCblhcsMhbNh3HIrIQGywq07MLH5hjBgAAAfLSURBVAz8HrgSaADWATe7+5tJdT4PvMfd/8zMlgGfcPebzGwB8ENgETAN+CVwZrDagNtMZ+HChV5XVzf0vQTiPT0c2vI2LatfZPMP1lA/70x2fvI6frTxXSaX5HPfzRdw8azU8/sPffMnJ/Rdg0k+/dP3FE7y6aL8RecROdiR+CWdl8ehDdsgFMJiMQr27ad8+06m7NxJ4Vs78VCI9nPPpu2i8zh0Rg1HJlcRLS0hlp8HZlgsRvhwF5G2dvL2NlPw9m6KttZTvGkLOe0die8uLqbrzDl0V5YTz82FXXvIa2unqKWFnIOJOkcmTaT9nPkcOvMMDs+s5sikiURLionl50M/PS1353BPjNZDPbR0dnOg81hwtHf1cPBwlI4jUTK5/skM8iNh8nNC5IRDREJGOGyEzQiFEj9zwiHyckLkRULkB6FSkBtJhEtOmPzgkxdJ1MsNh8jLCQc/E/O5kaTtB5+Q9f6EkBmRPt8bSloWCsLLcdzBg3+HY/thGIm6Zon9CgVldvQnCkEZEWa23t0XZlo/kx7DIqA+eE8zZrYSWAok/xJfCnw1mF4FfMsS/6OXAivd/Qiww8zqg+2RwTZHzMfue4HNe9qIY0AVfPRTAJRu28/1F1bzlWsXnJynNkIhoqUlKfOQuOT10ORJHJo8iX1f/CwTdu6m8rnfUL72FWZ+f2XGm++aMokDl1xI+3vOoTkKR0pL0ofWpe9hwu5GSl5/k5INb1L66gaqnn3xuO3Fw2EIh1j/2P8lnn9s8N7Mgl/MEarL099KHnenqyfG4e4Yh3tiHInG6Y7GORKN0xON0x1LfKKxOD0xpycWJ+5OPA4xd+Ke+AWcKHM6uqK0BnW7Y8e20ROUncrMoDcujgYLiUJLqgMcDSU8EVK9Zcdv79j6vesalvI4mPGKqN7mep996Ltf6Qy2XyOxT8nf3vtvm/wHwVD/7S2pVcn//q985Uryc8Ij0OLBZRIM1cDupPkG4NL+6rh71MzagMqg/Hd91q0OpgfbJgBmdjtwezDbYWZbM2hzxt4A/k//iycC2fvmm33ARuDxoyUjs78fOmvwOieH7D6+x9P+nsIm/MOgVQba31lD+a6TfvDZ3R8AHhiP7zazuqF0v0512t/spv3NbiO5v5lcftMIJF/+Mj0oS1vHzCJAKYlB6P7WzWSbIiIyDjIJhnXAPDObbWa5wDKgtk+dWuDWYPoG4BlPjLTVAsvMLM/MZgPzgJcz3KaIiIyDQU8lBWMGdwBrSFxa+pC7bzKzu4E6d68FHgRWBIPLLSR+0RPUe4LEoHIU+IK7xwDSbXPkd2/YxuUU1jjS/mY37W92G7H9HfRyVREROb2c1g/RExGR4ykYREQkhYIhDTNbYmZbzazezJaPd3tGgpnNMLNnzexNM9tkZn8elFeY2S/MbFvwszwoNzO7L/g3eMPMLhrfPTgxZhY2s1fN7KfB/GwzWxvs1+PBxQ8EF0g8HpSvNbOa8Wz3iTCzMjNbZWZbzGyzmb03m4+vmX0x+L+80cx+aGb52XZ8zewhM2sys41JZUM+pmZ2a1B/m5ndmu67kikY+ggeAXI/cA2wALg5eLTHqS4K/A93XwBcBnwh2K/lwK/cfR7wq2AeEvs/L/jcDnx77Js8Iv4c2Jw0fw9wr7vPBVpJPMeL4GdrUH5vUO9U803gaXefD5xPYr+z8viaWTVwJ7DQ3c8lcRHLMrLv+H4fWNKnbEjH1MwqgL8jcRPxIuDvesOkX+6uT9IHeC+wJmn+y8CXx7tdo7CfPybxrKqtwNSgbCqwNZj+DonnV/XWP1rvVPmQuD/mV8AVwE9JPHVgHxDpe6xJXCH33mA6EtSz8d6HIexrKbCjb5uz9fhy7GkLFcHx+ilwdTYeX6AG2HiixxS4GfhOUnlKvXQf9RiOl+4RINX91D0lBd3oC4G1wGR3fydYtBeYHExnw7/DvwFfAnof7VoJHHD3aDCfvE8pj3UBeh/rcqqYDTQDDwenzr5nZoVk6fF190bgX4FdwDskjtd6svf4JhvqMR3ysVYwnGbMrAj4L+Av3L09eZkn/pzIiuuXzexaoMnd1493W8ZIBLgI+La7Xwgc4tgpBiDrjm85iQdvzibx5OZCjj/lkvVG65gqGI6XtY/rMLMcEqHwA3f/76D4XTObGiyfCjQF5af6v8MfANeZ2U5gJYnTSd8EyoLHtkDqPvX3WJdTRQPQ4O5rg/lVJIIiW4/vR4Ad7t7s7j3Af5M45tl6fJMN9ZgO+VgrGI6XlY/rMDMjcYf6Znf/RtKi5MeZ3Epi7KG3/DPBlQ6XAW1J3deTnrt/2d2nu3sNiWP4jLvfAjxL4rEtcPz+pnusyynB3fcCu82s99G2i0k8cSArjy+JU0iXmVlB8H+7d3+z8vj2MdRjuga4yszKg57WVUFZ/8Z7YOVk/AAfJfEiobeA/zXe7RmhfbqcRJfzDeC14PNREudZfwVsI/EipYqgvpG4OustYAOJqz/GfT9OcN8/BPw0mJ5D4nld9cB/AnlBeX4wXx8snzPe7T6B/bwAqAuO8Y+A8mw+vsDfA1tIPDx+BZCXbceXxIvO3gF6SPQKbzuRYwr8abDv9cCfDPa9eiSGiIik0KkkERFJoWAQEZEUCgYREUmhYBARkRQKBhERSaFgEBGRFAoGERFJ8f8BQLxnwNGRX5EAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sn.distplot(lengths, color='crimson')\n",
    "sn.distplot(tot_lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further, it seems that short sentences were more likely to be mislabelled than longer ones. The above graph shows the distribution of lengths for the test set in BLUE and and the mislabeled test set in RED."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Pick one language that interests you, and one treebank for that language ,and try to build a POS tagger for this language. what the state of the art roughly is for your selected language and treebank. Did you come close?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "fnames = [f for f in listdir() if '.conllu' in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_dict = {}\n",
    "for file in fnames:\n",
    "    with open(file, 'r') as f:\n",
    "        data = f.read().split('sent_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_sen_data(file):\n",
    "    \n",
    "    with open(file, 'r') as f:\n",
    "        data = f.read().split('# sent_id')\n",
    "        \n",
    "    current_sentence = []\n",
    "    sentences = []\n",
    "    OneWord=namedtuple(\"OneWord\",[\"word\", \"pos_label\"])\n",
    "    for s in data:\n",
    "        if s:\n",
    "            lines = s.split('\\n') \n",
    "            i = lines.index('')\n",
    "            for l in lines[:i]:\n",
    "                if '#' in l:\n",
    "                    if current_sentence:\n",
    "                        sentences.append(current_sentence)\n",
    "                        current_sentence=[]\n",
    "                        pos = 0\n",
    "                    else:\n",
    "                        continue\n",
    "                #columns = l[1], l.split()[3],l.split()[4]\n",
    "                if l[0].isdigit():\n",
    "                    columns = [l.split()[1], l.split()[3]]\n",
    "                    current_sentence.append(OneWord(*columns))\n",
    "    return sentences\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['af_afribooms-ud-test.conllu',\n",
       " 'af_afribooms-ud-train.conllu',\n",
       " 'af_afribooms-ud-dev.conllu']"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_train=list(prep_sen_data(\"af_afribooms-ud-train.conllu\"))\n",
    "sentences_dev=list(prep_sen_data(\"af_afribooms-ud-dev.conllu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1314, 193)"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences_train), len(sentences_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'word_En': 1}, {'word_ons': 1}, {'word_hoop': 1}, {'word_hierdie': 1}, {'word_keer': 1}, {'word_dat': 1}, {'word_hernude': 1}, {'word_pogings': 1}, {'word_deur': 1}, {'word_die': 1}, {'word_internasionale': 1}, {'word_gemeenskap': 1}, {'word_om': 1}, {'word_blywende': 1}, {'word_oplossings': 1}, {'word_vir': 1}, {'word_hierdie': 1}, {'word_konflik': 1}, {'word_te': 1}, {'word_vind': 1}, {'word_,': 1}, {'word_vrugte': 1}, {'word_sal': 1}, {'word_afwerp': 1}, {'word_sodat': 1}, {'word_die': 1}, {'word_Israeliete': 1}, {'word_en': 1}, {'word_die': 1}, {'word_Palestyne': 1}, {'word_as': 1}, {'word_bure': 1}, {'word_vrede': 1}, {'word_en': 1}, {'word_sekuriteit': 1}, {'word_kan': 1}, {'word_geniet': 1}, {'word_binne': 1}, {'word_hul': 1}, {'word_soewereine': 1}, {'word_gebiede': 1}, {'word_.': 1}]\n"
     ]
    }
   ],
   "source": [
    "def generate_sentence_features(sent):\n",
    "    #Given a sentence as a list of (word, label) pairs\n",
    "    #generate the features for every word\n",
    "    #The result should be a list of same length as the sentence\n",
    "    #Each item is a dictionary of {\"feature name\"->feature value} mappings, holding all features of the word at that position\n",
    "    \n",
    "    sent_features=[] #this will be the result\n",
    "    for one_word in sent:\n",
    "        #We do nothing with label\n",
    "        #it just happens to be around\n",
    "        word_features={}\n",
    "        word_features[\"word_\"+one_word.word]=1 #the word itself is a feature\n",
    "        sent_features.append(word_features)\n",
    "    return sent_features\n",
    "\n",
    "print(generate_sentence_features(sentences_dev[0])  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "#...now we can generate the training examples\n",
    "def prep_data(sentences):\n",
    "    all_labels=[] #here we gather labels for all words in all sentences\n",
    "    all_features=[] #here we gather features for all words in all sentences\n",
    "    for sentence in sentences:\n",
    "        sent_features=generate_sentence_features(sentence)\n",
    "        assert len(sent_features)==len(sentence)\n",
    "        #Now we can get, for every position its label and its features\n",
    "        for one_word,features in zip(sentence,sent_features):\n",
    "            all_labels.append(one_word.pos_label) #label\n",
    "            all_features.append(features)         #and features to go with it\n",
    "    return all_labels, all_features\n",
    "\n",
    "train_labels,train_features=prep_data(sentences_train)\n",
    "dev_labels,dev_features=prep_data(sentences_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer vocab size: 5079\n",
      "Train shape (33889, 5079)\n",
      "Dev shape (5305, 5079)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "vectorizer=DictVectorizer()\n",
    "vectorizer.fit(train_features)\n",
    "print(\"Vectorizer vocab size:\",len(vectorizer.vocabulary_))\n",
    "\n",
    "feature_vectors_train=vectorizer.transform(train_features)\n",
    "feature_vectors_dev=vectorizer.transform(dev_features)\n",
    "\n",
    "print(\"Train shape\",feature_vectors_train.shape)\n",
    "print(\"Dev shape\",feature_vectors_dev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.05, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=1)"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import sklearn.svm\n",
    "\n",
    "classifier=sklearn.svm.LinearSVC(C=0.05,verbose=1)\n",
    "classifier.fit(feature_vectors_train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8452403393025447"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(feature_vectors_dev,dev_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape (33889, 14981)\n",
      "Dev shape (5305, 14981)\n",
      "[LibLinear]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9236569274269557"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_sentence_features(sent):\n",
    "    #Given a sentence as a list of (word, label) pairs\n",
    "    #generate the features for every word\n",
    "    #The result should be a list of same length as the sentence\n",
    "    #Each item is a dictionary of {\"feature name\"->feature value} mappings, holding all features of the word at that position\n",
    "    \n",
    "    sent_features=[] #this will be the result\n",
    "    for word_idx, one_word in enumerate(sent):\n",
    "        #We do nothing with label\n",
    "        #it just happens to be around\n",
    "        word_features={}\n",
    "        word_features[\"word_\"+one_word.word]=1 #the word itself is a feature\n",
    "        if word_idx!=0:\n",
    "            word_features[\"left_word_\"+sent[word_idx-1].word]=1\n",
    "        if word_idx!=len(sent)-1:\n",
    "            word_features[\"right_word_\"+sent[word_idx+1].word]=1\n",
    "        sent_features.append(word_features)\n",
    "    return sent_features\n",
    "\n",
    "train_labels,train_features=prep_data(sentences_train)\n",
    "dev_labels,dev_features=prep_data(sentences_dev)\n",
    "vectorizer=DictVectorizer()\n",
    "vectorizer.fit(train_features)\n",
    "feature_vectors_train=vectorizer.transform(train_features)\n",
    "feature_vectors_dev=vectorizer.transform(dev_features)\n",
    "\n",
    "print(\"Train shape\",feature_vectors_train.shape)\n",
    "print(\"Dev shape\",feature_vectors_dev.shape)\n",
    "\n",
    "classifier=sklearn.svm.LinearSVC(C=1,verbose=1)\n",
    "classifier.fit(feature_vectors_train, train_labels)\n",
    "classifier.score(feature_vectors_dev,dev_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is suspicious,  the highest performance according to the website is 97.82% for africaans.\n",
    "\n",
    "1. UDPipe Future (Praha)                   \tsoftware1-P\t97.82\n",
    "\n",
    "At first I achieved 84.52%, which is not terrible. However, with the latter pipeline I acheived 92.37% which is better. To only be 5% off the best performance is nice, it is reasonably close for a first attempt :) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will continue to see if I can close that gap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
